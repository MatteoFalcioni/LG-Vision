{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f549f80",
   "metadata": {},
   "source": [
    "# Parallel Processing for Street View Analysis\n",
    "\n",
    "## Overview\n",
    "This notebook implements parallel processing for analyzing thousands of Street View images using LangGraph with multiple concurrent nodes.\n",
    "\n",
    "## Problem Statement\n",
    "- **Scale**: Thousands of locations × multiple orientations (horizon/ground/sky) = 10k+ images\n",
    "- **Bottleneck**: Sequential AI model calls would take hours\n",
    "- **Solution**: Parallel processing with bounded concurrency\n",
    "\n",
    "## Architecture\n",
    "- **Input**: CSV with Street View URLs (from `google_apis.ipynb`)\n",
    "- **Processing**: LangGraph parallel nodes for vision analysis\n",
    "- **Output**: Graded/analyzed results per image\n",
    "\n",
    "## Concurrency Strategy\n",
    "- **Measure**: Single call latency (L) for vision model\n",
    "- **Calculate**: k ≈ T × L (where T = target throughput)\n",
    "- **Start**: k=16 nodes, scale up based on provider limits\n",
    "- **Monitor**: 429 errors, latency percentiles, success rates\n",
    "\n",
    "## Key Considerations\n",
    "- **Provider Limits**: API rate limits and concurrent request caps\n",
    "- **Rate Limiting**: Client-side throttling to avoid 429s\n",
    "- **Retry Logic**: Exponential backoff with jitter\n",
    "- **Checkpointing**: Idempotent tasks to avoid duplicate billing\n",
    "- **Budget Guards**: Max requests per minute/hour\n",
    "\n",
    "## Implementation Plan\n",
    "1. Load CSV and create work queue\n",
    "2. Implement bounded concurrency with LangGraph\n",
    "3. Add retry logic and rate limiting\n",
    "4. Monitor metrics and scale accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc118e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(str(Path().absolute().parent))  # This makes the parent directory available so you can use clean absolute imports like from src.graph import ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505a2cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using OPENAI model\n"
     ]
    }
   ],
   "source": [
    "from src.state import MultiState\n",
    "from src.prompts import multimodal_prompt\n",
    "from src.models import get_multimodal_model\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain.agents import create_agent\n",
    "from typing import Literal\n",
    "from langgraph.types import Command\n",
    "from src.utils import prepare_multimodal_message\n",
    "\n",
    "multimodal_model = get_multimodal_model()\n",
    "multimodal_agent = create_agent(\n",
    "    model=multimodal_model,\n",
    "    tools=[],\n",
    "    system_prompt=multimodal_prompt\n",
    ")\n",
    "\n",
    "def get_data_node(state: MultiState):\n",
    "    \"\"\"\n",
    "    Splits the csv into chunks and passes a single chunk to each agent parallel node\n",
    "    \"\"\"\n",
    "    # do we need this? Im thinking: pass just a portion of csvs to each agent parallel node\n",
    "    return \n",
    "\n",
    "async def multimodal_node(state: MultiState) -> Command[Literal[\"__end__\"]]:   # after multimodal -> stop (could change later)\n",
    "    \"\"\"\n",
    "    Handles multimodal inputs with multimodal model\n",
    "    \"\"\"\n",
    "\n",
    "    # construct multimodal input message\n",
    "    multimodal_msg = prepare_multimodal_message(state)  # returns HumanMessage\n",
    "\n",
    "    # clear history of last message to swap last one with the new, multimodal one\n",
    "    history = state.get(\"messages\", [])[:-1] if state.get(\"messages\", []) else []\n",
    "    updated_history = history + [multimodal_msg]  # LG wants lists to concatenate messages\n",
    "\n",
    "    result = await multimodal_agent.ainvoke({\"messages\": updated_history})\n",
    "    last_msg = result[\"messages\"][-1]\n",
    "\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\" : [last_msg],  # must be a list\n",
    "            \"images\" : [],  # clearing images after invocation, keep memory lightweight\n",
    "        },\n",
    "        goto=END\n",
    "    )\n",
    "\n",
    "def join_node(state: MultiState):\n",
    "    \"\"\"\n",
    "    Join the results from the multimodal agents\n",
    "    \"\"\"\n",
    "    # do we need this?\n",
    "    return \n",
    "\n",
    "def build_parallel_graph(checkpointer, n_nodes=2,save_display=False) -> StateGraph:\n",
    "    \"\"\"\n",
    "    Get the builder for the graph\n",
    "    \"\"\"\n",
    "    builder = StateGraph(MultiState)\n",
    "    # nodes\n",
    "    builder.add_node(\"get_data\", get_data_node)\n",
    "    builder.add_node(\"join\", join_node)\n",
    "    for i in range(n_nodes):\n",
    "        builder.add_node(f\"multimodal_agent_{i}\", multimodal_node)\n",
    "    # edges\n",
    "    # Need to investigate more on parallel edges: do i need to join? Do i use `Send`?\n",
    "    builder.add_edge(START, \"get_data\")\n",
    "    for i in range(n_nodes):\n",
    "        builder.add_edge(f\"get_data\", f\"multimodal_agent_{i}\")\n",
    "        builder.add_edge(f\"multimodal_agent_{i}\", \"join\")\n",
    "    builder.add_edge(\"join\", END)\n",
    "\n",
    "    graph = builder.compile(checkpointer=checkpointer)\n",
    "\n",
    "    if save_display:\n",
    "        # save the graph display to file\n",
    "        img = graph.get_graph().draw_mermaid_png() # returns bytes\n",
    "        # save the bytes to file \n",
    "        with open(\"./graph.png\", \"wb\") as f:\n",
    "            f.write(img)\n",
    "        print(\"Graph display saved to ./src/graph.png\")\n",
    "\n",
    "    return graph"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph-multimodal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
